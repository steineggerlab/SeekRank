{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsbNNWuiBAuq"
      },
      "source": [
        "# Installing Facebook embeddings template"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwwpHDgUixe0"
      },
      "source": [
        "!pip install git+https://github.com/facebookresearch/esm.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7KgzmFAjEPE"
      },
      "source": [
        "import torch\n",
        "import esm\n",
        "\n",
        "# Load 34 layer model\n",
        "model, alphabet = esm.pretrained.esm1_t34_670M_UR50S()\n",
        "model = model.cuda()\n",
        "\n",
        "batch_converter = alphabet.get_batch_converter()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLZEFi4ELNRt"
      },
      "source": [
        "import random\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M90c7UnGKUz2"
      },
      "source": [
        "def batch(iterable, n=1):\n",
        "    l = len(iterable)\n",
        "    for ndx in range(0, l, n):\n",
        "        yield iterable[ndx:min(ndx + n, l)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDuv4cuTBU0i"
      },
      "source": [
        "# PART 1: Generating prediction model\n",
        "\n",
        "# 1.1 Preparing data for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV4u_FtppuRz"
      },
      "source": [
        "# Prepare data (two protein sequences)\n",
        "\n",
        "FASTA_PATH='''/path/to/the/fasta ''' # Fasta to train\n",
        "\n",
        "data=[]\n",
        "ys = []\n",
        "Xs = []\n",
        "for header, sequence in esm.data.read_fasta(FASTA_PATH):\n",
        "  data.append((header, sequence))\n",
        "  body = (header.split(' '))[-1]\n",
        "  ys.append(float(body))\n",
        "print(ys)\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PriXt7l5Joep"
      },
      "source": [
        "# checking for memory storage (refresh if necessary)\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWV2t8O9BkTt"
      },
      "source": [
        "# 1.2 Building embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q99U7HLdPJB"
      },
      "source": [
        "sequence_embeddings = []\n",
        "# build embeddings\n",
        "for batch_seqs in batch(data,10):\n",
        "    batch_labels, batch_strs, batch_tokens = batch_converter(batch_seqs)\n",
        "\n",
        "    # Extract per-residue embeddings (on GPU)\n",
        "    batch_tokens_cuda = batch_tokens.to(device=\"cuda\", non_blocking=True)\n",
        "    with torch.no_grad():\n",
        "        results = model(batch_tokens_cuda, repr_layers=[34])\n",
        "    token_embeddings = results[\"representations\"][34]\n",
        "    # Generate per-sequence embeddings via averaging\n",
        "    # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "    for i, (_, seq) in enumerate(batch_seqs):\n",
        "        sequence_embeddings.append(token_embeddings[i, 1:len(seq) + 1].mean(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw1Oou7Yo1Dt"
      },
      "source": [
        "print(len(sequence_embeddings[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dtkb9Oi1Bvcr"
      },
      "source": [
        "# 1.3 Creating Training set & Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5-Fo9C4KZOL"
      },
      "source": [
        "# split training and test set\n",
        "Xs=[t.cpu().data.numpy() for t in sequence_embeddings]\n",
        "train_size = 0.8\n",
        "Xs_train, Xs_test, ys_train, ys_test = train_test_split(Xs, ys, train_size=train_size, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEHcrGIpB6UF"
      },
      "source": [
        "# 1.4 Beginning of the training block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pesb6f6xXRo_"
      },
      "source": [
        "knn_grid = {\n",
        "    'n_neighbors': [5, 10],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
        "    'leaf_size' : [15, 30],\n",
        "    'p' : [1, 2],\n",
        "}\n",
        "\n",
        "svm_grid = {\n",
        "    'C' : [0.1, 1.0, 10.0],\n",
        "    'kernel' :['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'degree' : [3],\n",
        "    'gamma': ['scale'],\n",
        "}\n",
        "\n",
        "rfr_grid = {\n",
        "    'n_estimators' : [100],\n",
        "    'criterion' : ['squared_error', 'absolute_error'],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'min_samples_split' : [2, 10],\n",
        "    'min_samples_leaf': [1, 4]\n",
        "}\n",
        "lgr_grid = {\n",
        "\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NIDqa1yXY7M"
      },
      "source": [
        "# Training Block!!!\n",
        "cls_list = [KNeighborsRegressor, SVR, RandomForestRegressor]\n",
        "param_grid_list = [knn_grid, svm_grid, rfr_grid]\n",
        "result_list = []\n",
        "grid_list = []\n",
        "for cls_name, param_grid in zip(cls_list, param_grid_list):\n",
        "    print(cls_name)\n",
        "    grid = GridSearchCV(\n",
        "        estimator = cls_name(),\n",
        "        param_grid = param_grid,\n",
        "        scoring = 'r2',\n",
        "        verbose = 1,\n",
        "        n_jobs = -1 # use all available cores\n",
        "    )\n",
        "    grid.fit(Xs_train, ys_train)\n",
        "    result_list.append(pd.DataFrame.from_dict(grid.cv_results_))\n",
        "    grid_list.append(grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsaUveq3CDWp"
      },
      "source": [
        "# 1.5 Testing the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lS0CXQoCnJi"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "\n",
        "# Assuming grid_list, Xs_test, and ys_test are already defined\n",
        "\n",
        "for i, grid in enumerate(grid_list):\n",
        "    print(grid.best_estimator_)\n",
        "    print()\n",
        "\n",
        "    # Predictions\n",
        "    preds = grid.predict(Xs_test)\n",
        "\n",
        "    # Calculate Spearman's correlation\n",
        "    rho, p_value = scipy.stats.spearmanr(ys_test, preds)\n",
        "\n",
        "    # Create a DataFrame and save to CSV\n",
        "    df = pd.DataFrame({'Actual Kcat/Km': ys_test, 'Predicted Kcat/Km': preds})\n",
        "    csv_filename = f'grid_element_{i}_kcat_km_data.csv'\n",
        "    df.to_csv(csv_filename, index=False)\n",
        "    print(f'Data saved to {csv_filename}')\n",
        "\n",
        "    # Create scatter plot\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(ys_test, preds, alpha=0.7)\n",
        "    plt.xlabel('Actual Kcat/Km')\n",
        "    plt.ylabel('Predicted Kcat/Km')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Annotate with Spearman's rho\n",
        "    plt.annotate(f'Spearman\\'s rho = {rho:.2f}\\nP-value = {p_value:.2e}',\n",
        "                 xy=(0.05, 0.85), xycoords='axes fraction',\n",
        "                 fontsize=12, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor='black', facecolor='white'))\n",
        "\n",
        "    # Save plot as an image\n",
        "    img_filename = f'grid_element_{i}_kcat_km_plot.png'\n",
        "    plt.savefig(img_filename)\n",
        "    print(f'Plot saved to {img_filename}')\n",
        "    plt.close()\n",
        "\n",
        "    print('\\n', '-' * 80, '\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZwO1-seXzpj"
      },
      "source": [
        "for i, grid in enumerate(grid_list):\n",
        "    print(grid.best_estimator_)\n",
        "    print()\n",
        "    preds = grid.predict(Xs_test)\n",
        "    print(f'{scipy.stats.spearmanr(ys_test, preds)}')\n",
        "    print('\\n', '-' * 80, '\\n')\n",
        "    # Calculate Spearman's correlation\n",
        "    rho, p_value = scipy.stats.spearmanr(ys_test, preds)\n",
        "\n",
        "    # Create a DataFrame and save to CSV\n",
        "    df = pd.DataFrame({'Actual Values': ys_test, 'Predicted Values': preds})\n",
        "    csv_filename = f'grid_element_{i}_data.csv'\n",
        "    df.to_csv(csv_filename, index=False)\n",
        "    print(f'Data saved to {csv_filename}')\n",
        "\n",
        "    # Create scatter plot\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(ys_test, preds, alpha=0.7)\n",
        "    plt.title('Spearman Correlation between Actual and Predicted Values')\n",
        "    plt.xlabel('Actual Values')\n",
        "    plt.ylabel('Predicted Values')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Annotate with Spearman's rho\n",
        "    plt.annotate(f'Spearman\\'s rho = {rho:.2f}\\nP-value = {p_value:.2e}',\n",
        "              xy=(0.05, 0.75), xycoords='axes fraction',\n",
        "              fontsize=12, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor='black', facecolor='white'))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "\n",
        "\n",
        "# Calculate Spearman's correlation\n",
        "rho, p_value = scipy.stats.spearmanr(ys_test, preds)\n",
        "\n",
        "# Create scatter plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(ys_test, preds, alpha=0.7)\n",
        "plt.title('Spearman Correlation between Actual and Predicted Values')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.grid(True)\n",
        "\n",
        "# Annotate with Spearman's rho\n",
        "plt.annotate(f'Spearman\\'s rho = {rho:.2f}\\nP-value = {p_value:.2e}',\n",
        "              xy=(0.05, 0.95), xycoords='axes fraction',\n",
        "              fontsize=12, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor='black', facecolor='white'))\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NQFjjQB6MPIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq6iTaHXf-BQ"
      },
      "source": [
        "topredict=[('wt','MEPSSLELPADTVQRIAAELKCHPTDERVALHLDEEDKLRHFRECFYIPKIQDLPPVDLSLVNKDENAIYFLGNSLGLQPKMVKTYLEEELDKWAKIAAYGHEVGKRPWITGDESIVGLMKDIVGANEKEIALMNALTVNLHLLMLSFFKPTPKRYKILLEAKAFPSDHYAIESQLQLHGLNIEESMRMIKPREGEETLRIEDILEVIEKEGDSIAVILFSGVHFYTGQHFNIPAITKAGQAKGCYVGFDLAHAVGNVELYLHDWGVDFACWCSYKYLNAGAGGIAGAFIHEKHAHTIKPALVGWFGHELSTRFKMDNKLQLIPGVCGFRISNPPILLVCSLHASLEIFKQATMKALRKKSVLLTGYLEYLIKHNYGKDKAATKKPVVNIITPSHVEERGCQLTITFSVPNKDVFQELEKRGVVCDKRNPNGIRVAPVPLYNSFHDVYKFTNLLTSILDSAETKN'),('best_patent','MEPSSLELPADTVQRIAAELKCHPTDERVALHLDEEDKLRHFRECFYIPKIQDLPPVDLSLVNKDEDAIYFNGNSLGLQPKMVKTYLEEELDKWAKIAINGWFEGDSPWIHYDESIVGLMKDIVGANEKEIVLMNTLTVNLHLLMLSFFKPTPKRYKILLEAKAFPSDHYAIESQLQLHGLNIEESMRIIKPREGEETLRIEDILEVIEKEGDSIAVILFSGIHYYTGQHFNIPAITKAGQAKGCYVGFDLAHAVGNVELYLHDWGVDFACWCGYKYLNSSPGGIAGAFIHEKHAHTIKPALVGWFGHELSTRFKMDNKLQLIPGVCGFRCSTPPILLVCILHASLEIFKQATMKALRKKSVLLTGYLEYLIKHNYGKDKAATKKPVVNIITPSHVEERGCQLTLTFNVPNKDVFQELEKRGVVCDKRNPNGIRVAPVPLYNSFHDVYKFTNLLTSILDSAETKN'),('best_mut','MEPSSLELPADTVQRIAAELKCHPTDERVALHLDEEDKLRHFRECFYIPKIQDLPPVDLSLVNKDEDAIYFNGNSLGLQPKMVKTYREEELDKWAKIAINGWFEGDSPWIHYDESIVGLMKDIVGANEKEIVLWYTLTHMLHLLMLSFFKPTPKRYKILLYAKAFPSDHYAIESQLQLHGLNIEESMRIIKPREGEETLRIEDILEVIEKEGDSIAVITFSGIHYMTGQHFNIPAITKALQAKGCYVGFDQAHAVGNVELYLHDWGVDFACNCGYKYLNSSPGWIQGWFCHEKHAHTIKPALVGWFGHELSTRFKMDNKLQLIPGVCGFRCSTPNHWLVCILHAPLENFKQATMKALRKKSVLLTGYLEYLIKHNYGKDKAATKKPVVNIITPSHVEERGCQLTLTFNVPNKDVFQELEKRGVVCDKRNPNGIRVAPVPLYNSFHDVYKFTNLLTSILDSAETKN'),('worst_mut','MEPSSLELPADTVQRIAAELKCHPTDERVALHLDEEDKLRHFRECFYIPKIQDLPPVDLSLVNKDEDAIYFNGNSLGLQPKMVKTYYEEELDKWAKIAINGWFEGDSPWIHYDESIVGLMKDIVGANEKEIVLYFTLTDQLHLLMLSFFKPTPKRYKILLNAKAFPSDHYAIESQLQLHGLNIEESMRIIKPREGEETLRIEDILEVIEKEGDSIAVIMFSGIHYETGQHFNIPAITKAMQAKGCYVGFDPAHAVGNVELYLHDWGVDFACVCGYKYLNSSPGIINGRFDHEKHAHTIKPALVGWFGHELSTRFKMDNKLQLIPGVCGFRCSTPKRKLVCILHAHLELFKQATMKALRKKSVLLTGYLEYLIKHNYGKDKAATKKPVVNIITPSHVEERGCQLTLTFNVPNKDVFQELEKRGVVCDKRNPNGIRVAPVPLYNSFHDVYKFTNLLTSILDSAETKN'),('var_93','MEPSPLELPADTVQRIASELRCHPTDERVALRLDEEDELRHFREYFYIPKMQDLPPIDLSLVNKDENAIYFLGNSLGLQPKMVKTYLEEELDKWAKMGAYGHEVGKRPWITGDETIVGLMTDIVGANEKEIALMNGLTVNLHLLLLSFFKPTPKRYKILLEAKAFPSDHYAIESQLQLHGLNVEKSMRIIKPREGEETLRTEDILEVIEKEGDSIAVILFSGVHFYTGQLFNIPAITKAGQAKGCFVGFDLAHAVGNVELHLHDWGVDFACWCSYKYLNSGAGGLAGAFVHEKHAYTIKPALVGWFGHELSTRFKMDNKLQLIPGVNGFRISNPPILLVCSLHASLEIFKQATMKALRRKSILLTGYLEYLIKHYYSKDKAETKKPIVNIITPSRIEERGCQLTLTFSVPMKYVFQELEKRGVVCDKREPNGIRVAPVPLYNSFHDVYKFIELLTSVLDSAETK')]\n",
        "\n",
        "for batch_seqs in batch(topredict, 1):\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(batch_seqs)\n",
        "  # build embeddings\n",
        "  batch_tokens_cuda = batch_tokens.to(device=\"cuda\", non_blocking=True)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    results = model(batch_tokens_cuda, repr_layers=[34])\n",
        "  token_embeddings = results[\"representations\"][34]\n",
        "\n",
        "  # Generate per-sequence embeddings via averaging\n",
        "  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "  sequence_embeddings = []\n",
        "  for i, (_, seq) in enumerate(batch_seqs):\n",
        "    sequence_embeddings.append(token_embeddings[i, 1:len(seq) + 1].mean(0))\n",
        "\n",
        "  predict_seqs_embeddings=[t.cpu().data.numpy() for t in sequence_embeddings]\n",
        "  preds=[]\n",
        "  for grid in grid_list:\n",
        "    pred = grid.predict(predict_seqs_embeddings)\n",
        "    preds.append(pred)\n",
        "  for i in range(0, len(batch_seqs)):\n",
        "    #f.write(\"{} {} {} {}\\n\".format(batch_seqs[i][0], preds[0][i],  preds[1][i],  preds[2][i]))\n",
        "    print(batch_seqs[i][0], preds[0][i], preds[1][i], preds[2][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAEuEnRMDE8V"
      },
      "source": [
        "# PART 2: Building embeddings (completely new data) & feed it into the prediction model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AvRQVkIgQPm"
      },
      "source": [
        "METAGENOME_FASTA_PATH=\"/path/to/fasta/to/predict\"\n",
        "\n",
        "\n",
        "topredict = []\n",
        "with open('/output/file', 'w') as f:\n",
        "  for header, sequence in esm.data.read_fasta(METAGENOME_FASTA_PATH):\n",
        "    topredict.append((header, sequence))\n",
        "\n",
        "  for batch_seqs in batch(topredict, 1):\n",
        "    batch_labels, batch_strs, batch_tokens = batch_converter(batch_seqs)\n",
        "    # build embeddings\n",
        "    batch_tokens_cuda = batch_tokens.to(device=\"cuda\", non_blocking=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      results = model(batch_tokens_cuda, repr_layers=[34])\n",
        "    token_embeddings = results[\"representations\"][34]\n",
        "\n",
        "    # Generate per-sequence embeddings via averaging\n",
        "    # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "    sequence_embeddings = []\n",
        "    for i, (_, seq) in enumerate(batch_seqs):\n",
        "      sequence_embeddings.append(token_embeddings[i, 1:len(seq) + 1].mean(0))\n",
        "\n",
        "    predict_seqs_embeddings=[t.cpu().data.numpy() for t in sequence_embeddings]\n",
        "    preds=[]\n",
        "    for grid in grid_list:\n",
        "      pred = grid.predict(predict_seqs_embeddings)\n",
        "      preds.append(pred)\n",
        "    for i in range(0, len(batch_seqs)):\n",
        "      f.write(\"{} {} {} {}\\n\".format(batch_seqs[i][0], preds[0][i],  preds[1][i],  preds[2][i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w976y3wIAtuB"
      },
      "source": [
        "# PART 3: Emptying cuda cache"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1FCZMyMkWnd"
      },
      "source": [
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}